#!/usr/bin/python26
#Description: Incremental restore script

import time
import os
import consts
import sys
import signal
import socket
import tempfile
import Queue
from threading import Thread
from mc_bin_client import MemcachedClient
from logger import Logger
from config import Config
from util import natural_sortkey, setup_sqlite_lib, getcommandoutput, get_checkpoints_frombackup, gethostname
import pdb
from download_client import download_client
import getopt
import commands
import json

DAY_EPOCH = 60*60*24

# Setup the sqlite3 LD_LIBRARY_PATH before importing sqlite3
setup_sqlite_lib()

def epoch2date(epoch):
    lt = time.gmtime(epoch)
    return time.strftime('%Y-%m-%d',lt)

class Restore:

    def __init__(self, vb_id, host, storage_server, ss_port):
        self.processlist = Queue.Queue()
        self.s3_lock_file = None
        self.exit_status = 0
        self.restore_complete = False
        self.vb_id = vb_id
        self.host = host
        self.storage_server = storage_server
        self.ss_port = ss_port
        try:
            self.config = Config(consts.CONFIG_FILE)
            self.config.read()
            self.logger = Logger(tag = self.config.syslog_tag, level = self.config.log_level)
        except Exception, e:
            self.config.syslog_tag = consts.SYSLOG_TAG
            self.logger = Logger(tag = self.config.syslog_tag, level = self.config.log_level)
            self.logger.log("FAILED: Parsing config file (%s)" %(str(e)))
            self.exit(1)

        self.logger.log("=== Starting Membase Restore ===")

        #self.cloud = self.config.cloud
        #self.game_id = self.config.game_id

        buffer_list = self.config.buffer_list.split(',')
        #append vb_id to the buffer list so that we can run restores in parallel
        for i in range(len(buffer_list)):
            buffer_list[i] = buffer_list[i] + '/' + 'vb_' + self.vb_id

        self.thread_count = len(buffer_list)
        self.free_buffer_list = Queue.Queue()
        self.download_queue = Queue.Queue()
        self.file_count = 0

        backup_process = self
        class stderrlog(object):
            def __init__(self, backup_process):
                self.parent = backup_process

            def write(self, err):
                self.parent.logger.log("FAILED: %s" %err)
                self.parent.exit(1)

        sys.stderr = stderrlog(backup_process)

        sys.stderr = stderrlog(self.logger)
        for b in buffer_list:
            os.system("mkdir -p %s" %b)
            rm_buffer_cmd = "find %s -type f -delete" %b
            self.logger.log("Clearing buffer %s" %b)
            status, output = self.getstatusoutput(rm_buffer_cmd)
            if status > 0:
                self.logger.log("FAILED: Clearing buffer %s (%s)" %(b, output))
                self.exit(1)
            self.free_buffer_list.put(b)

        self.restore_queue = Queue.Queue()
        signal.signal(signal.SIGINT, self.graceful_exit)
        signal.signal(signal.SIGQUIT, self.graceful_exit)
        signal.signal(signal.SIGTERM, self.graceful_exit)

    def setup_restore_env(self):
        self.logger.log("Setting up restore environment for membase server")

        hostname, port = self.host.split(':')

        if port == None or port == 0:
            self.logger.log("Invalid hostname or invalid port")
            sys.exit(1)

        """
                memcached_pid = int(open(consts.MEMCACHED_PID_FILE).read())

            try:
                os.kill(memcached_pid, 0)
                self.logger.log("Found running membase instance. Terminating" \
                        " membase process")
                os.kill(memcached_pid, 9)
            except:
                pass

        """

        self.logger.log("Setting min_data_age to 0")
        status, output = self.getstatusoutput("python26 %s %s set min_data_age 0" %(consts.PATH_MBFLUSHCTL, self.host))
        if status > 0:
            self.logger.log("FAILED: Unable to set min_data_age to 0 (%s)" %output)
            self.exit(1)


        #set the vbucket state in restore more
        status, outout = self.getstatusoutput("python26 %s %s set start_restore_vb %s" %(consts.PATH_MBFLUSHCTL, self.host, self.vb_id))

        if status > 0:
            self.loggher.log("FAILED: Unable to set vbucket in restore mode, check if vbucket is activated")
            self.exit(1)


    def _list_s3_files(self, s3path=None, complete=True, only_index=False):
        exclude_list = []
        found_dot_done = False
        ls_cmd = "%s ls %s" %(consts.PATH_S3CMD_EXEC, s3path)
        if not only_index:
            self.logger.log("Executing command %s" %ls_cmd)

        status, output = self.execute_command(ls_cmd)
        if status !=0:
            self.logger.log("FAILED: Listing files failed for %s (%s)" %(s3path, output))
            return False
        else:
            files = output.split('\n')
                #files = map(lambda x: 's3://'+x.split('s3://')[-1], lines)

        i = 0
        for f in files:
            f = files[i] = f.strip('\r')
            i = i + 1
            if f.endswith('done'):
                found_dot_done = True

            if f.endswith('manifest.del'):
                self.logger.log("Downloading delete manifest file")
                dlmanifest_cmd = '%s get %s /tmp/manifest.del' \
                        %(consts.PATH_S3CMD_EXEC, f)
                status, output = self.execute_command(dlmanifest_cmd)
                if status > 0:
                    self.logger.log("WARNING: Unable to download" \
                            "delete manifest file (%s)" %output)
                else:
                    exclude_lines = open('/tmp/manifest.del').readlines()
                    for l in exclude_lines:
                        exclude_list.append("%s%s" %(s3path, os.path.basename(l.strip())))

        if complete == False:
            complete = found_dot_done

        if only_index:
            mbb_files = filter(lambda x: x.endswith('.split'), files)
            #Remove the -00001.mbb from exclude list files and create uniq .split filenames
            exclude_list = set(map(lambda x: "%s.split" %"-".join(x.split('-')[:-1]), exclude_list))
            mbb_files = list(set(mbb_files) - set(exclude_list))
        else:
            mbb_files = filter(lambda x: x.endswith('.mbb'), files)
            mbb_files = list(set(mbb_files) - set(exclude_list))

        if complete == False:
            return []

        return mbb_files

    def _download_file(self, vb_id, path, filepath=None):
        download_instance = download_client(self.storage_server, self.ss_port)
        retries = self.config.download_retries
        self.logger.log("Info: Downloading file %s" %path)
        for i in range(retries):
            if i > 0:
                self.logger.log("Info: Retrying download for file %s" %path)

            status, buffer = download_instance.download(vb_id, path, filepath)
            if len(buffer) > 0:
                break

        if filepath != None:
            if os.path.getsize(filepath) > 0:
                self.logger.log("SUCCESS: Completed downloading file %s  (retries=%d)" %(path, i))
                return 0, None
            else:
                self.logger.log("FAILED: Downloading file %s failed " %(path))
                return -1, None

        else:
            if len(buffer) == 0:
                self.logger.log("FAILED: Downloading file %s failed " %(path))
                return -1, None
            else:
                self.logger.log("SUCCESS: Completed downloading file %s  (retries=%d)" %(path, i))
                return 0, buffer


    def _list_path(self, vb_id, path=None):
        download_instance = download_client(self.storage_server, self.ss_port)
        retries = self.config.download_retries
        self.logger.log("Info: Listing path %s" %path)
        for i in range(retries):
            if i > 0:
                self.logger.log("Info: Retrying listing for path %s" %path)

            status, buffer = download_instance.list(vb_id, path)
            if status == 0:
                break

        if status != 0:
            self.logger.log("FAILED: Listing for path %s failed " %(path))
            return -1, None
        else:
            self.logger.log("SUCCESS: Completed listing file  %s  (retries=%d)" %(path, i))
            return 0, buffer


    def _delete_file(self, vb_id, path):
        download_instance = download_client(self.storage_server, self.ss_port)
        retries = self.config.download_retries
        self.logger.log("Info: deleting file %s" %path)
        for i in range(retries):
            if i > 0:
                self.logger.log("Info: retrying delete for path %s" %path)

            status = download_instance.remove(vb_id, path)
            if status == True:
                break

        if status == False:
            self.logger.log("FAILED: Deleting file %s failed " %(path))
            return -1, None
        else:
            self.logger.log("SUCCESS: Completed deleting file  %s  (retries=%d)" %(path, i))
            return 0, True


    def _add_lock(self, vb_id, path):
        download_instance = download_client(self.storage_server, self.ss_port)
        retries = self.config.download_retries
        self.logger.log("Info: Adding lock %s" %path)
        for i in range(retries):
            if i > 0:
                self.logger.log("Info: retrying adding lock for file %s" %path)

            status = download_instance.add_lock(vb_id, path)
            if status == True:
                break

        if status == False:
            self.logger.log("FAILED: adding lock failed %s failed " %(path))
            return -1, None
        else:
            self.logger.log("SUCCESS: Completed adding lock  %s  (retries=%d)" %(path, i))
            return 0, True


    #convert s3 like command to download client command
    # s3cmd_zynga get path download_path ==> download_client._download(vb_id, path, download_path)
    def execute_command(self, command, filepath=None):

        command_tokens = command.split()

        if "get" in command_tokens[1]:
            return self._download_file( self.vb_id, command_tokens[2], filepath)
        elif "ls" in command_tokens[1]:
            if len(command_tokens) > 2:
                return self._list_path(self.vb_id, command_tokens[2])
            else:
                return self._list_path(self.vb_id)
        elif "rm" in command_tokens[1] or "del" in command_tokens[1]:
            return self._delete_file(self.vb_id, command_tokens[2])
        elif "addlock" in command_tokens[1]:
            return self._add_lock(self.vb_id, command_tokens[2])
        else:
            self.logger.log("FAILED: Invaid command %s" %command)
            return -1, None


    def graceful_exit(self, signum=None, frame=None):
        for process in self.processlist.queue:
            try:
                process.terminate()
            except:
                pass
        self.clean_s3_lock()
        if os.path.exists(consts.MBRESTORE_PID_FILE):
            os.unlink(consts.MBRESTORE_PID_FILE)
        self.logger.log("Restore process terminated")
        os._exit(self.exit_status)

    def exit(self, status):
        self.exit_status = status
        if status != 0:
            self.graceful_exit()
        else:
            if os.path.exists(consts.MBRESTORE_PID_FILE):
                os.unlink(consts.MBRESTORE_PID_FILE)
            os._exit(self.exit_status)


    def getstatusoutput(self, cmd):
        return getcommandoutput(cmd, self.processlist)

    def clean_s3_lock(self):
        if self.s3_lock_file:
            rm_cmd = "%s del %s" %(consts.PATH_S3CMD_EXEC, self.s3_lock_file)
            for i in range(self.config.upload_retries):
                status, output = self.execute_command(rm_cmd)
                if i > 0:
                    self.logger.log("Retrying to remove incremental backup directory lock in s3")
                if status == 0:
                    return
            self.logger.log("FAILED: Unable to remove s3 incremental directory lock")
            os._exit(1)

    def verify_split_index(self, base_s3_path, files):
        backup_index_list = self._list_s3_files(base_s3_path, True, True)
        tmp = files[:]
        for index_file in backup_index_list:
            tmpfile = tempfile.mktemp()
            files_in_index = []
            if not self._download_file(self.vb_id, index_file, tmpfile):
                self.logger.log("FAILED: Unable to download split_index file, %s" %index_file)
                self.exit(1)
            files_in_index = map(lambda x: "%s%s" %(base_s3_path, x.strip()), open(tmpfile).readlines())
            os.unlink(tmpfile)

            for f in files_in_index:
                if f in tmp:
                    tmp.remove(f)
                else:
                    self.logger.log("FAILED: Split verification - %s not found" %f)
                    self.exit(1)

        if len(tmp) != 0:
            self.logger.log("FAILED: Split verification - found invalid files %s" %str(tmp))
            self.exit(1)

    def fetch_backuplist(self):
        """
        Get the list of backup files which are to be downloaded
        """
        self.logger.log("Fetching Backup list from S3")
        epoch = time.time()
        self.logger.log("Fetching list of incremental backups")
        incremental_backup_s3_path = "incremental/"

        incremental_backup_list = self._list_s3_files(incremental_backup_s3_path)
        if not incremental_backup_list:
            self.logger.log("Could not find any incremental backups")
            incremental_backup_list = []
        else:
            self.verify_split_index(incremental_backup_s3_path, incremental_backup_list)
            hostname = gethostname()
            self.s3_lock_file = "%s.lock-%s" %(incremental_backup_s3_path, hostname)
            lock_cmd = "%s addlock %s" %(consts.PATH_S3CMD_EXEC, self.s3_lock_file)
            status, output = self.execute_command(lock_cmd)
            if status > 0:
                self.logger.log("FAILED: Unable to put incremental backup directory lock in s3")
                self.s3_lock_file = None
                self.exit(1)
            else:
                self.logger.log("Locked incremental backup directory in s3")

        master_backup_epoch = epoch
        self.logger.log("Searching for master backup")
        for attempt in xrange(consts.MAX_BACKUP_SEARCH_TRIES):
            date = epoch2date(master_backup_epoch)
            master_s3_path = '%s/%s/' %(consts.MASTER_DIRNAME, date)
            master_backup_list = self._list_s3_files(master_s3_path, False)
            if len(master_backup_list):
                self.logger.log("Found master backup for date, %s" %epoch2date(master_backup_epoch))
                self.verify_split_index(master_s3_path, master_backup_list)
                master_backup_epoch += DAY_EPOCH
                break
            else:
                master_backup_epoch -= DAY_EPOCH
                if attempt == consts.MAX_BACKUP_SEARCH_TRIES - 1:
                    self.logger.log("Could not find master backup. Maximum tries exceeded")
                    master_backup_list = []

        self.logger.log("Fetching list of periodic backups")
        periodic_backup_list = []
        for date_epoch in xrange(int(master_backup_epoch), int(epoch) + DAY_EPOCH, DAY_EPOCH):
            date = epoch2date(date_epoch)
            periodic_s3_path = '%s/%s/' %(consts.PERIODIC_DIRNAME, date)
            periodic_file_list = self._list_s3_files(periodic_s3_path, False)
            self.verify_split_index(periodic_s3_path, periodic_file_list)
            if not periodic_file_list:
                self.logger.log("Could not find periodic backup for %s" %date)
            periodic_backup_list.extend(periodic_file_list)

        incremental_backup_list.sort(key=natural_sortkey)
        incremental_backup_list.reverse()
        master_backup_list.sort(key=natural_sortkey)
        master_backup_list.reverse()
        periodic_backup_list.sort(key=natural_sortkey)
        periodic_backup_list.reverse()
        return incremental_backup_list + periodic_backup_list + master_backup_list

    def populate_queue(self):
        backup_files = self.fetch_backuplist()
        if len(backup_files) == 0:
            self.logger.log("No backup files found.")
            self.exit(2)

        for f in backup_files:
            self.logger.log("Found file %s" %f)

        if not backup_files:
            self.exit(1)

        for i,f in enumerate(backup_files):
            self.download_queue.put((i, f, 'backup-%05d.mbb' %i))

        self.file_count = len(self.download_queue.queue)

    def _do_online_restore(self, backup_file, complete=False):
        self.logger.log("Performing restore from %s" %backup_file)
        if complete:
            restore_cmd = "python26 %s -h %s -c %s" %(consts.PATH_MBRESTORE_EXEC, self.host, backup_file)
        else:
            restore_cmd = "python26 %s -h %s %s" %(consts.PATH_MBRESTORE_EXEC, self.host, backup_file)

        self.logger.log("Executing command %s" %restore_cmd)
        status, output = self.getstatusoutput(restore_cmd)
        if status == 0:
            return True
        else:
            self.logger.log("FAILED: Executing command %s (%s)"  %(restore_cmd, output))
            return False

    def perform_restore(self):
        try:
            shard = 0
            last_checkpoint = None
            last_file_checkpoints = None
            while shard < self.file_count:
                self.logger.log("RESTORE: Waiting for backup file %d/%d" %(shard+1, self.file_count))
                restore_list = list(self.restore_queue.queue)
                restore_list.sort()
                if len(restore_list) > 0 and shard == restore_list[0][0]:
                    self.logger.log("Processing backup file %d/%d" %(shard+1, self.file_count))
                    backup = restore_list[0]
                    self.restore_queue.queue.remove(backup)
                    backup_file = backup[1]
                    buffer_path = backup[2]
                    try:
                        checkpoints = get_checkpoints_frombackup(backup_file)
                    except Exception, e:
                        self.logger.log("FAILED: sqlite file %s is corrupt (%s)" %(backup_file, str(e)))
                        self.exit(1)

                    if shard > 0:
                        #Ignore ordering verification we last file has got same checkpoints (splits of same backup)
                        if not last_file_checkpoints == checkpoints:
                            if not (last_checkpoint == checkpoints[-1] or last_checkpoint - 1 == checkpoints[-1]):
                                self.logger.log("FAILED: Checkpoint order mismatch. Last file checkpoint: %d Current file checkpoint: %d" %(last_checkpoint, checkpoints[-1]))
                                self.exit(1)
                    else:
                        try:
                            f = open(consts.LAST_CHECKPOINT_FILE, 'w')
                            f.write(str(checkpoints[-1]))
                            f.close()
                        except Exception, e:
                            self.logger.log("FAILED: Unable to write last_checkpoint file (%s)" %str(e))
                            self.exit(1)

                    last_checkpoint = checkpoints[0]
                    last_file_checkpoints = checkpoints
                    self.logger.log("Checkpoints in the current backup-file %s : %s" %(backup_file, str(checkpoints)))

                    complete = False
                    #NOTE: Do not switch back to normal mode from restore mode
                    #Master server will take care of restore mode switch
                    #if shard == self.file_count - 1:
                    #    complete = True
                    #else:
                    #    complete = False

                    status = self._do_online_restore(backup_file, complete)
                    if status:
                        os.unlink(backup_file)
                        self.free_buffer_list.put(buffer_path)
                        shard +=1
                    else:
                        self.exit(1)

                time.sleep(1)

            self.restore_complete = True
        except Exception, e:
            self.logger.log("Thread stopped with exception (%s)" %str(e))
            self.exit(1)

    def download_files(self):
        while True:
            self.logger.log("Waiting for obtaining download buffer")
            backup = self.download_queue.get()
            self.logger.log("SUCCESS: Attempt to obtain a file for download %s" %str(backup))
            buffer_path = self.free_buffer_list.get()
            self.logger.log("Obtained buffer %s" %buffer_path)
            status,output = self._download_file(self.vb_id, backup[1], '%s/%s' %(buffer_path, backup[2]))
            if status == 0:
                self.restore_queue.put((backup[0], '%s/%s' %(buffer_path, backup[2]), buffer_path))
            else:
                self.logger.log("Failure, could not add buffer to queue ")
                self.exit(1)

            self.download_queue.task_done()

    def main(self):
        start_time = int(time.time())
        if os.getuid() != 0:
            print "Please run as root"
            sys.exit(1)

        if os.path.exists(consts.MBRESTORE_PID_FILE):
            pid = int(open(consts.MBRESTORE_PID_FILE, 'r').read())
            try:
                os.kill(pid, 0)
                self.logger.log("Restore process is already running with PID %d" %pid)
                sys.exit(1)
            except:
                pass
        fd = open(consts.MBRESTORE_PID_FILE,'w')
        fd.write(str(os.getpid()))
        fd.close()

        self.populate_queue()
        for i in range(self.thread_count):
            t = Thread(target=self.download_files)
            t.daemon = True
            t.start()
        t = Thread(target=self.perform_restore)
        t.daemon = True
        t.start()

        while not self.restore_complete:
            time.sleep(10)

        end_time = int(time.time())
        self.clean_s3_lock()
        status, outout = self.getstatusoutput("python26 %s %s set complete_restore_vb %s" %(consts.PATH_MBFLUSHCTL, self.host, self.vb_id))

        if status > 0:
            self.logger.log("FAILED: complete_restore command failed")

        f = open(consts.MEMCACHED_SYSCONFIG_FILE)
        sysconfig = f.read().split(';')
        param, endlimiter = sysconfig[-1].split("'")
        sysconfig = sysconfig[:-1]
        sysconfig.append(param)
        for p in sysconfig:
            if 'restore_mode' in p:
                sysconfig.remove(p)

            if 'min_data_age' in p:
                dataage = p.split('=')[-1]
                self.logger.log("Resetting min_data_age to %s" %dataage)
                status, output = self.getstatusoutput("python26 %s 0:11211 set min_data_age %s" %(consts.PATH_MBFLUSHCTL, dataage))
                if status > 0:
                    self.logger.log("FAILED: Unable to set min_data_age to %s (%s)" %(dataage, output))
                    self.exit(1)

        sysconfig_str = ";".join(sysconfig)
        sysconfig_str += "'%s" %endlimiter
        f = open(consts.MEMCACHED_SYSCONFIG_FILE, 'w')
        f.write(sysconfig_str)
        f.close()

        self.logger.log("Restore completed successfully in %d seconds" %(end_time-start_time))
        self.exit(0)

if __name__ == '__main__':
    if os.getuid() != 0:
        print "Please run as root"
        sys.exit(1)


    if os.path.exists(consts.MBRESTORE_PID_FILE):
        pid = int(open(consts.MBRESTORE_PID_FILE).read())
        try:
            os.kill(pid, 0)
            print "Restore process with PID:%d is already running" %pid
            os._exit(1)
        except:
            pass


    options, remainder = getopt.getopt(sys.argv[1:], 'v:d:p:', ['vb_id=',
                                                                'disk_mapper=',
                                                                'port=',
                                                             ])
    vb_id = -1
    port = 0
    disk_mapper = ''
    for opt, arg in options:
        if opt in ('-v', '--vb_id'):
            vb_id = arg
        elif opt in ('-p', '--port'):
            port = arg
        elif opt in ('-d', '--disk_mapper'):
            disk_mapper = arg

    if vb_id == -1 or disk_mapper == '':
        print ("Please specify vb_id and disk_mapper host");
        print "Usage membase-restore -v <vb_id> -d <disk_mapper> [-p port]"
        sys.exit(1)

    if port == 0:
        port = "11211"

    host="127.0.0.1:" + port
    ## diskmapper integration get storage server ip corresponding to this vb_id
    map_available = False
    for i in range(consts.CONNECT_RETRIES):
        vb_query_cmd = "curl -s \"http://" + disk_mapper + "/api?action=get_vb_mapping&&vbucket=vb_" + str(vb_id) + "\""
        status, output = commands.getstatusoutput(vb_query_cmd)

        if status > 0:
            print "Failure: Unable to fetch disk mapping. Command %s output %s" %(fetch_map_cmd, output)
            if i >= consts.CONNECT_RETRIES:
                break
            continue
        elif status == 0:
            try:
                current_map = json.loads(output)
                map_available = True
                storage_server = current_map['storage_server']
                break
            except Exception, e:
                print"Unable to parse output %s" %str(e)
                break


    if map_available == False:
        # Failure no map available :(
        sys.exit(1)

    print "Storage server %s" %storage_server


    ss_port = 22122

    vb_id =  str(vb_id).zfill(2)
    restore = Restore(vb_id, host, storage_server, ss_port)
    restore.setup_restore_env()
    restore.main()
