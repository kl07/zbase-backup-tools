#!/usr/bin/python26
#Description: Incremental merge script

import time
import os
import consts
import commands
from logger import Logger
from config import Config
import Queue
from threading import Thread
from util import natural_sortkey, setup_sqlite_lib
import sys
import getopt
setup_sqlite_lib()

DAY_EPOCH = 60*60*24
PID_FILE = '/var/run/mbmerge.pid'

def epoch2date(epoch):
    lt = time.localtime(epoch)
    return time.strftime('%Y-%m-%d',lt)

def parse_args():
    options = {}
    try:
        opts, args = getopt.getopt(sys.argv[1:], 'h:o:l:')
    except getopt.GetoptError, err:
        print str(err)
        sys.exit(2)
    for o,a in opts:
        if o == '-h':
            options['hostname'] = a
        elif o == '-o':
            options['output'] = a
        elif o == '-l':
            options['filelog'] = a
        else:
            assert False, "Unknown option"

    if len(options) != 3:
        print "Usage: %s -h hostname -l s3list.txt -o merged_file.mbb" %sys.argv[0]
        print "More arguments required"
        sys.exit(2)
    return options

class Merge:

    def __init__(self, output_file, filelog, cloud=None, game_id=None, hostname=None):
        try:
            self.config = Config(consts.configfile)
            self.config.read()
            self.logger = Logger(tag = self.config.syslog_tag, level = self.config.log_level)
        except Exception, e:
            self.config.syslog_tag = consts.SYSLOG_TAG
            self.logger = Logger(tag = self.config.syslog_tag, level = self.config.log_level)
            self.logger.log("FAILED: Parsing config file (%s)" %(str(e)))

        if cloud == None:
            self.cloud = self.config.cloud
        else:
            self.cloud = cloud
        if game_id == None:
            self.game_id = self.config.game_id
	else:
            self.game_id = game_id
        if hostname == None:
            self.hostname = self.config.hostname
        else:
            self.hostname = hostname

        self.output_file = output_file
        self.s3filelist = filelog
        buffer_list = self.config.buffer_list.split(',')
        self.thread_count = len(buffer_list)

        self.free_buffer_list = Queue.Queue()
        self.download_queue = Queue.Queue()
        self.file_count = 0

        for b in buffer_list:
            self.free_buffer_list.put(b)
        self.merge_queue = Queue.Queue()

    def _list_s3_files(self, s3path):
        ls_cmd = "%s ls %s" %(consts.PATH_S3CMD_EXEC, s3path)
        self.logger.log("Executing command %s" %ls_cmd)
        status, output = commands.getstatusoutput(ls_cmd)
	if status !=0:
            self.logger.log("FAILED: %s" %output)
            return False
	else:
            lines = output.split('\n')
            files = map(lambda x: 's3://'+x.split('s3://')[-1], lines)
            mbb_files = filter(lambda x: x.endswith('.mbb'), files)
            return mbb_files

    def _download_file(self, s3path, filepath):
        get_cmd = "%s sync %s %s" %(consts.PATH_S3CMD_EXEC, s3path, filepath)
        retries = self.config.download_retries
        self.logger.log("Executing command %s" %get_cmd)
        for i in range(retries):
            if i > 0:
                self.logger.log("Retrying download for %s" %s3path)
            status, output = commands.getstatusoutput(get_cmd)
            self.logger.log("Downloading file %s to %s" %(s3path, filepath))
            if status == 0:
                break

    	if status !=0:
            self.logger.log("FAILED: %s" %output)
            return False
        else:
            self.logger.log("Completed downloading file %s" %s3path)
            return True

    def exit(self, status):
        self.logger.log("Error occured")
        os._exit(status)

    def fetch_backuplist(self):
        """
        Get the list of backup files which are to be downloaded
        """

        self.logger.log("Fetching Backup list from S3")
        epoch = time.time()
	incremental_backup_list = self._list_s3_files('s3://%s/%s/%s/%s/%s/' %(self.config.s3bucket, self.cloud, self.game_id, self.hostname, consts.INCR_DIRNAME))
        self.incremental_backup_list = incremental_backup_list

        self.logger.log("Fetching list of incremental backups")
        if not incremental_backup_list:
            self.logger.log("Could not find any incremental backups")
            return False
	return [ x for x in reversed(sorted(incremental_backup_list, key=natural_sortkey)) ]

    def populate_queue(self):
        backup_files = self.fetch_backuplist()
	if backup_files == False:
		sys.exit(1)
        for f in backup_files:
            self.logger.log("Found file %s" %f)
        if not backup_files:
            self.exit(1)
        for i,f in enumerate(backup_files):
            self.download_queue.put((i, f, 'backup-%05d.mbb' %i))
        self.file_count = len(self.download_queue.queue)

    def _do_merge(self, backup_file):
        self.logger.log("Performing merge using from %s" %backup_file)
        merge_cmd = "python26 %s -o %s %s" %(consts.PATH_MBMERGE_EXEC, self.output_file, backup_file)

        self.logger.log("Executing command %s" %merge_cmd)
        status, output = commands.getstatusoutput(merge_cmd)
        if status == 0:
            return True
        else:
            self.logger.log("FAILED: Executing command %s (%s)"  %(merge_cmd, output))
            return False

    def perform_merge(self):
        shard = 0
        while shard < self.file_count:
            self.logger.log("Checking for backup file with shard %d" %shard)
            merge_list = list(self.merge_queue.queue)
            merge_list.sort()
            self.logger.log("Merge Queue %s" %str(merge_list))
            if len(merge_list) > 0 and shard == merge_list[0][0]:
                backup = merge_list[0]
                self.merge_queue.queue.remove(backup)
                backup_file = backup[1]
                buffer_path = backup[2]
                status = self._do_merge(backup_file)
                if status:
                    os.unlink(backup_file)
                    self.free_buffer_list.put(buffer_path)
                    shard +=1
                else:
                    self.exit(1)
            time.sleep(1)


    def download_files(self):
        while True:
            self.logger.log("Attempt to obtain a file for download")
            backup = self.download_queue.get()
            self.logger.log("SUCCESS: Attempt to obtain a file for download %s" %str(backup))
            buffer_path = self.free_buffer_list.get()
            self.logger.log("Obtained buffer %s" %buffer_path)
            status = self._download_file(backup[1], '%s/%s' %(buffer_path, backup[2]))
            self.logger.log("Download complete")
            if status:
                self.merge_queue.put((backup[0], '%s/%s' %(buffer_path, backup[2]), buffer_path))
            else:
                self.exit(1)
            self.download_queue.task_done()

    def main(self):

        if os.path.exists(PID_FILE):
            pid = int(open(PID_FILE, 'r').read())
            try:
                os.kill(pid, 0)
                self.logger.log("Merge process is already running with PID %d" %pid)
                sys.exit(1)
            except:
                pass
        fd = open(PID_FILE,'w')
        fd.write(str(os.getpid()))
        fd.close()

        self.populate_queue()
        for i in range(self.thread_count):
            t = Thread(target=self.download_files)
            t.daemon = True
            t.start()
        t = Thread(target=self.perform_merge)
        t.daemon = True
        t.start()

        self.download_queue.join()
        t.join()
        f = open(self.s3filelist, 'w')
        for i in self.incremental_backup_list:
            f.write(i+'\n')
        f.close()
        self.logger.log("Merge completed successfully. Merged file can be found at %s" %self.output_file)

if __name__ == '__main__':
    args = parse_args()
    merge = Merge(output_file=args['output'], filelog=args['filelog'], hostname=args['hostname'])
    merge.main()

