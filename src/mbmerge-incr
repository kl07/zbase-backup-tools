#!/usr/bin/python26
#Description: Incremental merge script

import time
import os
import consts
import signal
import Queue
import sys
import getopt
from threading import Thread
from logger import Logger
from config import Config
from util import natural_sortkey, setup_sqlite_lib, getcommandoutput

#Setup ld_path for sqlite3
setup_sqlite_lib()

DAY_EPOCH = 60*60*24

def epoch2date(epoch):
    lt = time.localtime(epoch)
    return time.strftime('%Y-%m-%d',lt)

def parse_args():
    options = {'exclude_list':None}
    try:
        opts, args = getopt.getopt(sys.argv[1:], 'h:o:l:x:')
    except getopt.GetoptError, err:
        print str(err)
        sys.exit(2)

    for o,a in opts:
        if o == '-h':
            options['hostname'] = a
        elif o == '-o':
            options['output'] = a
        elif o == '-l':
            options['filelog'] = a
        elif o == '-x':
            options['exclude_list'] = a
        else:
            assert False, "Unknown option"

    if len(options) < 3:
        print "Usage: %s -h hostname -l s3list.txt -x exclude_list.txt -o merged_file.mbb" %sys.argv[0]
        print "More arguments required"
        sys.exit(2)
    return options

class Merge:

    def __init__(self, output_file, filelog, exclude_list=None, cloud=None, game_id=None, hostname=None):
        self.merge_queue = Queue.Queue()
        self.processlist = Queue.Queue()
        self.exit_status = 0
        self.merge_complete = False
        try:
            self.config = Config(consts.CONFIG_FILE)
            self.config.read()
            self.logger = Logger(tag = self.config.syslog_tag, level = self.config.log_level)
        except Exception, e:
            self.config.syslog_tag = consts.SYSLOG_TAG
            self.logger = Logger(tag = self.config.syslog_tag, level = self.config.log_level)
            self.logger.log("FAILED: Parsing config file (%s)" %(str(e)))

        if cloud == None:
            self.cloud = self.config.cloud
        else:
            self.cloud = cloud

        if game_id == None:
            self.game_id = self.config.game_id
	else:
            self.game_id = game_id

        if hostname == None:
            self.hostname = self.config.hostname
        else:
            self.hostname = hostname

        self.exclude_list = exclude_list
        self.output_file = output_file
        self.s3filelist = filelog
        buffer_list = self.config.buffer_list.split(',')
        self.thread_count = len(buffer_list)
        self.free_buffer_list = Queue.Queue()
        self.download_queue = Queue.Queue()
        self.file_count = 0
        for b in buffer_list:
            self.free_buffer_list.put(b)

        signal.signal(signal.SIGINT, self.graceful_exit)
        signal.signal(signal.SIGQUIT, self.graceful_exit)
        signal.signal(signal.SIGTERM, self.graceful_exit)


    def graceful_exit(self, signum=None, frame=None):
        for process in self.processlist.queue:
            try:
                process.terminate()
            except:
                pass

        os.unlink(consts.MBMERGE_PID_FILE)
        self.logger.log("Merge process terminated")
        os._exit(self.exit_status)

    def exit(self, status):
        self.exit_status = status
        self.graceful_exit()

    def _list_s3_files(self, s3path):
        ls_cmd = "%s ls %s" %(consts.PATH_S3CMD_EXEC, s3path)
        self.logger.log("Executing command %s" %ls_cmd)
        status, output = self.getstatusoutput(ls_cmd)
	if status !=0:
            self.logger.log("FAILED: %s" %output)
            return False
	else:
            lines = output.split('\n')
            files = map(lambda x: 's3://'+x.split('s3://')[-1], lines)
            mbb_files = filter(lambda x: x.endswith('.mbb'), files)
            return mbb_files

    def getstatusoutput(self, cmd):
        return getcommandoutput(cmd, self.processlist)

    def _download_file(self, s3path, filepath):
        get_cmd = "%s sync %s %s" %(consts.PATH_S3CMD_EXEC, s3path, filepath)
        retries = self.config.download_retries
        self.logger.log("Executing command %s" %get_cmd)
        for i in range(retries):
            if i > 0:
                self.logger.log("Retrying download for %s" %s3path)
            status, output = self.getstatusoutput(get_cmd)
            self.logger.log("Downloading file %s to %s" %(s3path, filepath))
            if status == 0:
                break

    	if status !=0:
            self.logger.log("FAILED: %s" %output)
            return False
        else:
            self.logger.log("Completed downloading file %s" %s3path)
            return True

    def fetch_backuplist(self):
        """
        Get the list of backup files which are to be downloaded
        """

        self.logger.log("Fetching Backup list from S3")
        epoch = time.time()
	incremental_backup_list = self._list_s3_files('s3://%s/%s/%s/%s/%s/' %(self.config.s3bucket, self.cloud, self.game_id, self.hostname, consts.INCR_DIRNAME))
        if self.exclude_list:
            f = open(self.exclude_list)
            exclude_list_items = map(lambda x: x.strip(), f.readlines())
        else:
            exclude_list_items = []

        self.incremental_backup_list = list(set(incremental_backup_list) - set(exclude_list_items))
        self.logger.log("Fetching list of incremental backups")
        if not incremental_backup_list:
            self.logger.log("Could not find any incremental backups")
            return False

	return [ x for x in reversed(sorted(self.incremental_backup_list, key=natural_sortkey)) ]

    def populate_queue(self):
        backup_files = self.fetch_backuplist()
	if backup_files == False:
		sys.exit(1)

        for f in backup_files:
            self.logger.log("Found file %s" %f)

        if not backup_files:
            self.exit(1)

        for i,f in enumerate(backup_files):
            self.download_queue.put((i, f, 'backup-%05d.mbb' %i))

        self.file_count = len(self.download_queue.queue)

    def _do_merge(self, backup_file):
        self.logger.log("Performing merge using from %s" %backup_file)
        merge_cmd = "python26 %s -o %s %s" %(consts.PATH_MBMERGE_EXEC, self.output_file, backup_file)
        self.logger.log("Executing command %s" %merge_cmd)
        status, output = self.getstatusoutput(merge_cmd)
        if status == 0:
            return True
        else:
            self.logger.log("FAILED: Executing command %s (%s)"  %(merge_cmd, output))
            return False

    def perform_merge(self):
        shard = 0
        while shard < self.file_count:
            self.logger.log("Checking for backup file with shard %d" %shard)
            merge_list = list(self.merge_queue.queue)
            merge_list.sort()
            if len(merge_list) > 0 and shard == merge_list[0][0]:
                backup = merge_list[0]
                self.merge_queue.queue.remove(backup)
                backup_file = backup[1]
                buffer_path = backup[2]
                status = self._do_merge(backup_file)
                if status:
                    os.unlink(backup_file)
                    self.free_buffer_list.put(buffer_path)
                    shard +=1
                else:
                    self.exit(1)

            time.sleep(2)
        self.merge_complete = True

    def download_files(self):
        while True:
            self.logger.log("Attempt to obtain a file for download")
            backup = self.download_queue.get()
            self.logger.log("SUCCESS: Attempt to obtain a file for download %s" %str(backup))
            buffer_path = self.free_buffer_list.get()
            self.logger.log("Obtained buffer %s" %buffer_path)
            status = self._download_file(backup[1], '%s/%s' %(buffer_path, backup[2]))
            self.logger.log("Download complete")
            if status:
                self.merge_queue.put((backup[0], '%s/%s' %(buffer_path, backup[2]), buffer_path))
            else:
                self.exit(1)

            self.download_queue.task_done()

    def main(self):

        if os.path.exists(consts.MBMERGE_PID_FILE):
            pid = int(open(consts.MBMERGE_PID_FILE, 'r').read())
            try:
                os.kill(pid, 0)
                self.logger.log("Merge process is already running with PID %d" %pid)
                sys.exit(1)
            except:
                pass

        fd = open(consts.MBMERGE_PID_FILE,'w')
        fd.write(str(os.getpid()))
        fd.close()
        self.populate_queue()
        for i in range(self.thread_count):
            t = Thread(target=self.download_files)
            t.daemon = True
            t.start()

        t = Thread(target=self.perform_merge)
        t.daemon = True
        t.start()
        while not self.merge_complete:
            time.sleep(10)

        f = open(self.s3filelist, 'w')
        for i in self.incremental_backup_list:
            f.write(i+'\n')

        f.close()
        self.logger.log("Merge completed successfully. Merged file can be found at %s" %self.output_file)

if __name__ == '__main__':
    args = parse_args()
    merge = Merge(output_file=args['output'], filelog=args['filelog'], hostname=args['hostname'], exclude_list=args['exclude_list'])
    merge.main()

