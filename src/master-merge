#!/usr/bin/python26
#Description: Wrapper script that downloads, merges and uploads

import time
import os
import consts
import commands
from logger import Logger
from config import Config
import Queue
from threading import Thread
from util import natural_sortkey
import sys
import re
import getopt
import datetime
import fnmatch
import multiprocessing
from multiprocessing import Process, Value, Array
import re
import time
import shlex
import pdb
import glob
import tempfile
import subprocess

PID_FILE = '/var/run/merge.pid'

class MasterMerge(multiprocessing.Process):

    def __init__(self, pathname=None, token=None):
        multiprocessing.Process.__init__(self)

    def run(self):

        try:
            self.config = Config(consts.CONFIG_FILE)
            self.config.read()
            self.logger = Logger(tag = self.config.syslog_tag, level = self.config.log_level)
        except Exception, e:
            self.config.syslog_tag = consts.SYSLOG_TAG
            self.logger = Logger(tag = self.config.syslog_tag, level = self.config.log_level)
            self.logger.log("FAILED: Parsing config file (%s)" %(str(e)))

        self.game_id = self.config.game_id
        now=datetime.datetime.now()
        self.now = now
        self.timestamp = "%d-%02d-%02d_%02d:%02d:%02d" %(now.year,now.month,now.day,now.hour,now.minute,now.second)
        #get host name from the disk path
        status,output = commands.getstatusoutput("ls %s/" %pathname)
        if status != 0:
            self.logger.log("Cannot find any hostnames in path %s" %pathname)
            return

        hosts = output.split()
        if len(hosts) == 0:
            self.logger.log(" No directories to process in path %s" %pathname)
            return

        for hostname in hosts:
            self.scratch_dir = "/dev/shm/master-%s" %hostname
            os.system("mkdir -p %s" %self.scratch_dir)
            location = "%s/%s/%s/%s" %(consts.STORAGE_SERVER_ROOT, self.game_id, hostname, self.config.cloud)
            master_location = "%s/master" %location
            master_directory = "%s/%d-%02d-%02d" %(master_location, self.now.year, self.now.month, self.now.day)
            self.merged_file = "%s/merged-%d-%02d-%02d" %(master_directory, self.now.year, self.now.month, self.now.day)
            if os.path.isfile(self.merged_file) :
                self.logger.log("Info: Merged for this location %s already done today" %master_location)
                continue

            os.system("rm -f %s/*.mbb" %master_directory)
            os.system("rm -f %s/*.split" %master_directory)
            found_master = False
            merge_list = []
            datetime_object = datetime.date.today()
            for i in range(consts.MAX_BACKUP_LOOKUP_DAYS+1):
                difference = datetime.timedelta(days=-(i))
                datestamp = (datetime_object + difference).strftime('%Y-%m-%d')
                path = os.path.join(location, consts.MASTER_DIRNAME, datestamp)
                if os.path.exists(os.path.join(path, ".done")):
                    master_list = glob.glob("%s/*.mbb" %path)
                    if len(master_list) > 0:
                        found_master = True
                        break

                path = os.path.join(location, consts.PERIODIC_DIRNAME, datestamp)
                if os.path.exists(os.path.join(path, ".done")):
                    periodic_list = glob.glob("%s/*.mbb" %path)
                    periodic_list.sort()
                    periodic_list.reverse()
                    merge_list.extend(periodic_list)

            if found_master:
                master_list.sort()
                master_list.reverse()
                merge_list.extend(master_list)
            else:
                self.logger.log("No master backupfile found for host %s" %hostname)
                continue

            #self.logger.log("Going to merge files:")
            #for f in merge_list:
            #    self.logger.log("File: %s" %f)


            status = self.start_merge(master_location, master_directory, merge_list)
            status = True
            if status == False:
                self.logger.log(" Failed to create daily merged backup for hostname %s" %hostname)

            os.system("rm -rf %s" %self.scratch_dir)

        #increment token to allow another process to continue
        token.value += 1
        return

    def start_merge(self, master_location, master_directory, merge_list):

        os.system("mkdir -p %s" %master_directory)

        t_start = time.time()
        total_lines = len(merge_list)
        self.logger.log(" Info. starting merge for location %s. Files to merge %d" %(master_location, total_lines))
        if total_lines < 2:
            self.logger.log("Info: Too few files to merge. ")
            return True

        f = tempfile.NamedTemporaryFile(delete=False)
        for line in merge_list:
            f.write("%s\n" %line)
        f.close()

        split_file_name = "%s/backup-%s-%%.mbb" %(master_directory, self.timestamp)
        merge_cmd = "%s -o %s -i %s -s %d -v" %(consts.PATH_MBMERGE_EXEC,
                                        split_file_name, f.name, consts.SPLIT_SIZE)

        process = subprocess.Popen(shlex.split(merge_cmd), stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        status = 0
        while True:
            log = process.stdout.readline()
            rv = process.poll()
            if not log and rv != None:
                status = rv
                err = process.stderr.readline()
                if err:
                    self.logger.log("Err. %s" %err)
                break
            if log.strip() != '':
                self.logger.log("Info. %s" %log)
        os.unlink(f.name)

        if status != 0:
            self.logger.log ("Info. Merge failed")
            os.system("rm -f %s/*" %master_directory)
            return False

        t_end = time.time()

        # merge was successfull
        self.logger.log ("Info. Merge complete for %s. Took %d sec " %(master_location, (t_end - t_start)))

        t_end = time.time()


        # create a manifest.split file in the output directory. this contains the list
        # of split files that the restore script needs to verify
        manifest_split = "%s/backup-%s.split" %(master_directory, self.timestamp)

        status,output = commands.getstatusoutput("ls %s/*.mbb" %master_directory)
        if status != 0:
            self.logger.log(" Failed: Cannot find any files in path %s" %master_directory)
            return False

        lines = output.split()
        try:
            fd = open(manifest_split, "w")
        except:
            self.logger.log(" Failed: Cannot create manifest split %s" %manifest_split)
            return False

        for line in lines:
            try:
                fd.write(os.path.basename(line) + '\n')
            except:
                self.logger.log(" Failed: Cannot write manifest.split %s" %manifest_split)
                os.system("rm -f %s" %manifest_split)
                return False
        fd.close()

        #add a .done file to the output directory
        try:
            os.system("touch %s/.done" %master_directory)
        except:
            self.logger.log("Failed to add .done file to %s" %master_directory)

        os.system("touch %s" %self.merged_file)
        self.logger.log("Success: Master merge completed")

        return True


if __name__ == '__main__':

    if os.path.exists(PID_FILE):
        pid = int(open(PID_FILE, 'r').read())
        try:
            os.kill(pid, 0)
            print("Merge process is already running with PID %d" %pid)
            os._exit(1)
        except:
            pass
    fd = open(PID_FILE,'w')
    fd.write(str(os.getpid()))
    fd.close()

    part_no = 0
    if len(sys.argv) == 2:
        part_no = int(sys.argv[1])

    elif len(sys.argv) > 2:
        print
        print "Usage: %s <partition number>" %sys.argv[0]
        sys.exit(1)

    jobs = []
    token = Value('i', 3)

    today=datetime.datetime.date(datetime.datetime.now())
    partition = today.strftime("%w")

    if part_no == 0:
        part_no = int(partition) + 1

    pathname = "/data_%s" %part_no
    print "Operating on parition %s" %pathname


    for i in range(1):
        #pathname = "/data_%d" %(i+1)
        #pathname = "/data_3"
        #while token.value == 0:
            #wait until a token is available
            #time.sleep(60)

        merge = MasterMerge(pathname, token)
        token.value -= 1
        jobs.append(merge)
        merge.start()

    #jobs[-1].terminate()
    for j in jobs:
        j.join()

    os._exit(0)
