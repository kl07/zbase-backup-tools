#!/usr/bin/python26
#Description: Wrapper script that downloads, merges and uploads

import time
import os
import consts
import commands
from logger import Logger
from config import Config
import Queue
from threading import Thread
from util import natural_sortkey
import sys
import re
import getopt
import datetime
import fnmatch
import multiprocessing
from multiprocessing import Process, Value, Array
import re
import time
import pdb
import glob

PID_FILE = '/var/run/merge.pid'

class MasterMerge(multiprocessing.Process):

    def __init__(self, pathname=None, token=None):
        multiprocessing.Process.__init__(self)

    def run(self):

        try:
            self.config = Config(consts.CONFIG_FILE)
            self.config.read()
            self.logger = Logger(tag = self.config.syslog_tag, level = self.config.log_level)
        except Exception, e:
            self.config.syslog_tag = consts.SYSLOG_TAG
            self.logger = Logger(tag = self.config.syslog_tag, level = self.config.log_level)
            self.logger.log("FAILED: Parsing config file (%s)" %(str(e)))

        self.game_id = self.config.game_id
        now=datetime.datetime.now()
        self.now = now
        self.timestamp = "%d-%02d-%02d_%02d:%02d:%02d" %(now.year,now.month,now.day,now.hour,now.minute,now.second)
        #get host name from the disk path
        status,output = commands.getstatusoutput("ls %s/" %pathname)
        if status != 0:
            self.logger.log(" Cannot find any hostnames in path %s" %pathname)
            return

        hosts = output.split()
        if len(hosts) == 0:
            self.logger.log(" No directories to process in path %s" %pathname)
            return

        for hostname in hosts:
            #hostname = "pritish-inc-backup-test-002"
            self.scratch_dir = "/dev/shm/master-%s" %hostname
            os.system("mkdir -p %s" %self.scratch_dir)
            location = "%s/%s/%s/%s" %(consts.STORAGE_SERVER_ROOT, self.game_id, hostname, self.config.cloud)
            master_location = "%s/master" %location
            master_directory = "%s/%d-%02d-%02d" %(master_location, self.now.year, self.now.month, self.now.day)
            self.merged_file = "%s/merged-%d-%02d-%02d" %(master_directory, self.now.year, self.now.month, self.now.day)
            if os.path.isfile(self.merged_file) :
                self.logger.log("Info: Merged for this location %s already done today" %master_location)
                continue

            os.system("rm -f %s/*.mbb" %master_directory)
            found_master = False
            merge_list = []
            datetime_object = datetime.date.today()
            for i in range(consts.MAX_BACKUP_LOOKUP_DAYS+1):
                difference = datetime.timedelta(days=-(i))
                datestamp = (datetime_object + difference).strftime('%Y-%m-%d')
                path = os.path.join(location, consts.MASTER_DIRNAME, datestamp)
                if os.path.exists(os.path.join(path, ".done")):
                    master_list = glob.glob("%s/*.mbb" %path)
                    if len(master_list) > 0:
                        found_master = True

                path = os.path.join(location, consts.PERIODIC_DIRNAME, datestamp)
                if os.path.exists(os.path.join(path, ".done")):
                    periodic_list = glob.glob("%s/*.mbb" %path)
                    periodic_list.sort()
                    periodic_list.reverse()
                    merge_list.extend(periodic_list)

                if found_master:
                    break

            if found_master:
                master_list.sort()
                master_list.reverse()
                merge_list.extend(master_list)
            else:
                self.logger.log("No master backupfile found for host %s" %hostname)
                continue

            #self.logger.log("Going to merge files:")
            #for f in merge_list:
            #    self.logger.log("File: %s" %f)


            status = self.start_merge(master_location, master_directory, merge_list)
            status = True
            if status == False:
                self.logger.log(" Failed to create daily merged backup for hostname %s" %hostname)

            os.system("rm -rf %s" %self.scratch_dir)

        #increment token to allow another process to continue
        token.value += 1
        return

    def start_merge(self, master_location, master_directory, merge_list):

        os.system("mkdir -p %s" %master_directory)
        output_file = "%s/master-%s.mbb" %(master_directory, self.timestamp)
        self.logger.log(" Info. starting merge for location %s" %master_location)

        incr_backup1 = "%s/backup-001.mbb" %self.scratch_dir
        incr_backup2 = "%s/backup-002.mbb" %self.scratch_dir

        t_start = time.time()
        i = 0

        total_lines = len(merge_list)
        if total_lines < 2:
            self.logger.log("Info: Too few files to merge. ")
            return True

        while i < total_lines:
            cp_cmd1 = "dd if=%s of=%s iflag=direct bs=4096K" %(merge_list[i], incr_backup1)
            cp_cmd2 = "dd if=%s of=%s iflag=direct bs=4096K" %(merge_list[i+1], incr_backup2)
            cp_cmd3 = ""
            i+=2
            #odd number of files
            if total_lines%2 and (i+1) == total_lines:
                incr_backup3 = "%s/backup-003.mbb" %self.scratch_dir
                cp_cmd3 = "dd if=%s of=%s iflag=direct bs=4096K" %(merge_list[i], incr_backup3)
                i+=1

            try:
                os.system(cp_cmd1)
                os.system(cp_cmd2)
                if cp_cmd3:
                    os.system(cp_cmd3)

            except:
                self.logger.log("Failed. Unable to copy to scratch spacei %s" %self.scratch_dir)
                return False


            if cp_cmd3:
                merge_cmd =  " %s -o %s %s %s %s" %(consts.PATH_MBMERGE_EXEC, output_file, incr_backup1, incr_backup2, incr_backup3)
            else:
                merge_cmd = " %s -o %s %s %s" %(consts.PATH_MBMERGE_EXEC, output_file, incr_backup1, incr_backup2)

            #self.logger.log(" executing command %s" %merge_cmd)
            status, output = commands.getstatusoutput(merge_cmd)
            if status != 0:
                self.logger.log ("Failed to merge for location %s, output %s" %(master_location, output))
                os.system("rm -f %s*" %output_file)
                return False

            self.logger.log("Info. Progress %d/%d for %s" %(i, total_lines, output_file))

        t_end = time.time()

        # merge was successfull
        self.logger.log ("Info. Merge complete for %s. Took %d sec " %(output_file, (t_end - t_start)))

        file_size = os.path.getsize(output_file) / (1024 * 1024)

        if file_size > consts.SPLIT_SIZE:
            split_file_name = "%s/master-%s" %(master_directory, self.timestamp) + '-%.mbb'
            split_cmd = "%s -o %s -s %s %s" %(consts.PATH_MBMERGE_EXEC, split_file_name, consts.SPLIT_SIZE, output_file)
            self.logger.log("Info: Executing split command %s "%split_cmd)
            ts_start = time.time()
            status, output = commands.getstatusoutput(split_cmd)
            if status != 0:
                self.logger.log("Failed to split merged file. %s" %output)
                os.system("rm -f %s/*.mbb" %master_location)
                return False

            ts_end = time.time()

            self.logger.log("Info. Split complete for %s. Took %d sec. Total %d sec" %(output_file, (ts_end - ts_start),(ts_end - t_start)))

            #delete the original merged file
            os.system("rm -f %s" %output_file)

        #add a .done file to the output directory
        try:
            os.system("touch %s/.done" %master_directory)
        except:
            self.logger.log("Failed to add .done file to %s" %master_directory)

        os.system("touch %s" %self.merged_file)
        self.logger.log("Success: Master merge completed. %s" %output_file)

        return True


if __name__ == '__main__':

    if os.path.exists(PID_FILE):
        pid = int(open(PID_FILE, 'r').read())
        try:
            os.kill(pid, 0)
            print("Merge process is already running with PID %d" %pid)
            os._exit(1)
        except:
            pass
    fd = open(PID_FILE,'w')
    fd.write(str(os.getpid()))
    fd.close()

    if len(sys.argv) != 1:
        print
        print "Usage: %s <hostame list location>" %sys.argv[0]
        sys.exit(1)

    jobs = []
    token = Value('i', 3)

    for i in range(7):
        pathname = "/data_%d" %(i+1)
        #pathname = "/data_3"
        while token.value == 0:
            #wait until a token is available
            time.sleep(60)

        merge = MasterMerge(pathname, token)
        token.value -= 1
        jobs.append(merge)
        merge.start()

    #jobs[-1].terminate()
    for j in jobs:
        j.join()

    os._exit(0)
