#!/usr/bin/python26 
#Description: Incremental restore script

import time
import os
import consts
from logger import Logger
from config import Config
import Queue
from threading import Thread
from util import natural_sortkey, setup_sqlite_lib, getcommandoutput
import sys
import signal

DAY_EPOCH = 60*60*24
PID_FILE = '/var/run/mbrestore.pid'

setup_sqlite_lib()

import sqlite3

def epoch2date(epoch):
    lt = time.localtime(epoch)
    return time.strftime('%Y-%m-%d',lt)

class Restore:

    def __init__(self):
        try:
            self.config = Config(consts.configfile) 
            self.config.read()
            self.logger = Logger(tag = self.config.syslog_tag, level = self.config.log_level)
        except Exception, e:
            self.config.syslog_tag = consts.SYSLOG_TAG 
            self.logger = Logger(tag = self.config.syslog_tag, level = self.config.log_level)
            self.logger.log("FAILED: Parsing config file (%s)" %(str(e)))
            self.exit(1)
        self.logger.log("=== Starting Membase Restore ===")

        self.processlist = Queue.Queue()
        self.cloud = self.config.cloud 
        self.game_id = self.config.game_id
        self.hostname = self.config.hostname
        buffer_list = self.config.buffer_list.split(',')
        self.thread_count = len(buffer_list)
        self.free_buffer_list = Queue.Queue() 
        self.download_queue = Queue.Queue()
        self.file_count = 0
        logger_object = self.logger

        class stderrlog(object):
            def write(self, err):
                global logger_object
                logger_object.log("FAILED: %s" %err)
        sys.stderr = stderrlog
 
        for b in buffer_list:
            self.free_buffer_list.put(b) 
        self.restore_queue = Queue.Queue()

        signal.signal(signal.SIGINT, self.graceful_exit)
        signal.signal(signal.SIGQUIT, self.graceful_exit)
        signal.signal(signal.SIGTERM, self.graceful_exit)

    def _get_checkpoints_frombackup(self, backup_filepath):
        db = sqlite3.connect(backup_filepath)
        cursor = db.execute('select cpoint_id from cpoint_state')
        cpoint_list = map(lambda x: x[0], cursor.fetchall())
        return sorted(cpoint_list)

    def _list_s3_files(self, s3path, complete=True):
        ls_cmd = "%s ls %s" %(consts.PATH_S3CMD_EXEC, s3path)
        self.logger.log("Executing command %s" %ls_cmd)
        status, output = self.getstatusoutput(ls_cmd)
	if status !=0:
            self.logger.log("FAILED: %s" %output)
            return False
	else:
            lines = output.split('\n')
            files = map(lambda x: 's3://'+x.split('s3://')[-1], lines)
            if complete == False:
                for f in files:
                    if f.endswith('.done'):
                        complete = True
                        break

            mbb_files = filter(lambda x: x.endswith('.mbb'), files)
            if complete == False:
                return []
            return mbb_files 

    def _download_file(self, s3path, filepath):
        get_cmd = "%s sync %s %s" %(consts.PATH_S3CMD_EXEC, s3path, filepath)
        retries = self.config.download_retries
        self.logger.log("Executing command %s" %get_cmd)
        for i in range(retries):
            if i > 0:
                self.logger.log("Retrying download for %s" %s3path)
            status, output = self.getstatusoutput(get_cmd)
            self.logger.log("Downloading file %s to %s" %(s3path, filepath))
            if status == 0:
                break

	if status > 0:
            self.logger.log("FAILED: %s" %output)
            return False
        else:
            self.logger.log("SUCCESS: Completed downloading file %s to %s (retries=%d)" %(s3path, filepath, i))
            return True

    def graceful_exit(self, signum=None, frame=None):
        for process in self.processlist.queue:
            try:
                process.terminate()
            except:
                pass

        self.logger.log("Restore process terminated")
        os.unlink(PID_FILE)
        os._exit(self.exit_status)

    def exit(self, status):
        self.exit_status = status
        self.graceful_exit()

    def getstatusoutput(self, cmd):
        return getcommandoutput(cmd, self.processlist)

    def fetch_backuplist(self):
        """
        Get the list of backup files which are to be downloaded
        """
        self.logger.log("Fetching Backup list from S3")
        epoch = time.time()
        incremental_backup_list = self._list_s3_files('s3://%s/%s/%s/%s/%s/' %(self.config.s3bucket, self.cloud, self.game_id, self.hostname, consts.INCR_DIRNAME))
        self.logger.log("Fetching list of incremental backups")
        if not incremental_backup_list:
            self.logger.log("Could not find any incremental backups")
            incremental_backup_list = []

        master_backup_epoch = epoch 
        self.logger.log("Searching for master backup")
        for attempt in xrange(consts.MAX_BACKUP_SEARCH_TRIES):
            date = epoch2date(master_backup_epoch)
            master_backup_list = self._list_s3_files('s3://%s/%s/%s/%s/%s/%s/' %(self.config.s3bucket, self.cloud, self.game_id, self.hostname, consts.MASTER_DIRNAME, date), False)
            #if not master_backup_list:
            #    continue
            if len(master_backup_list):
                self.logger.log("Found master backup for date, %s" %epoch2date(master_backup_epoch))
                break
            else:
                master_backup_epoch -= DAY_EPOCH
                if attempt == consts.MAX_BACKUP_SEARCH_TRIES - 1:
                    self.logger.log("Could not find master backup. Maximum tries exceeded")
                    master_backup_list = []

        self.logger.log("Fetching list of periodic backups")
        periodic_backup_list = []
        for date_epoch in xrange(int(master_backup_epoch), int(epoch) + DAY_EPOCH, DAY_EPOCH):
            date = epoch2date(date_epoch)
            periodic_file_list = self._list_s3_files('s3://%s/%s/%s/%s/%s/%s/' %(self.config.s3bucket, self.cloud, self.game_id, self.hostname, consts.PERIODIC_DIRNAME, date), False)
            if not periodic_file_list:
                self.logger.log("Could not find periodic backup for %s" %date)
            periodic_backup_list.extend(periodic_file_list)
     
        incremental_backup_list.sort(key=natural_sortkey)
        incremental_backup_list.reverse()
        master_backup_list.sort(key=natural_sortkey)
        master_backup_list.reverse()
        periodic_backup_list.sort(key=natural_sortkey)
        periodic_backup_list.reverse()

        return incremental_backup_list + periodic_backup_list + master_backup_list 

    def populate_queue(self):
        backup_files = self.fetch_backuplist()
        if len(backup_files) == 0:
            self.logger.log("No backup files found.")
            self.exit(2)

        for f in backup_files:
            self.logger.log("Found file %s" %f)
        if not backup_files:
            self.exit(1)
        for i,f in enumerate(backup_files):
            self.download_queue.put((i, f, 'backup-%05d.mbb' %i))
        self.file_count = len(self.download_queue.queue)

    def _do_online_restore(self, backup_file, complete=False):
        self.logger.log("Performing restore from %s" %backup_file)
        if complete:
            restore_cmd = "python26 %s -h 127.0.0.1:11211 -c %s" %(consts.PATH_MBRESTORE_EXEC, backup_file)
        else:
            restore_cmd = "python26 %s -h 127.0.0.1:11211 %s" %(consts.PATH_MBRESTORE_EXEC, backup_file)

        self.logger.log("Executing command %s" %restore_cmd)
        status, output = self.getstatusoutput(restore_cmd)
        if status == 0:
            return True
        else:
            self.logger.log("FAILED: Executing command %s (%s)"  %(restore_cmd, output))
            return False

    def perform_restore(self):
        shard = 0
        last_checkpoint = None
        while shard < self.file_count:
            self.logger.log("RESTORE: Waiting for backup file %d/%d" %(shard+1, self.file_count))
            restore_list = list(self.restore_queue.queue)
            restore_list.sort()
            if len(restore_list) > 0 and shard == restore_list[0][0]:
                self.logger.log("Processing backup file %d/%d" %(shard+1, self.file_count))
                backup = restore_list[0]
                self.restore_queue.queue.remove(backup)
                backup_file = backup[1]
                buffer_path = backup[2]
                checkpoints = self._get_checkpoints_frombackup(backup_file)
                if shard == 0:
                    last_checkpoint = checkpoints[0]
                else:
                    if last_checkpoint - 1 != checkpoints[-1]:
                        self.logger.log("FAILED: Checkpoint order mismatch. Last file checkpoint: %d Current file checkpoint: %d" %(last_checkpoint, checkpoints[-1]))
                        self.exit(1)
                    else:
                        self.logger.log("Checkpoints in the current backup-file %s : %s" %(backup_file, str(checkpoints)))

                if shard == self.file_count - 1:
                    complete = True
                else:
                    complete = False
                status = self._do_online_restore(backup_file, complete)
                if status:
                    os.unlink(backup_file)
                    self.free_buffer_list.put(buffer_path)
                    shard +=1
                else:
                    self.exit(1)
            time.sleep(1)

    def download_files(self):
        while True:
            self.logger.log("Waiting for obtaining download buffer")
            backup = self.download_queue.get() 
            self.logger.log("SUCCESS: Attempt to obtain a file for download %s" %str(backup))
            buffer_path = self.free_buffer_list.get()
            self.logger.log("Obtained buffer %s" %buffer_path)
            status = self._download_file(backup[1], '%s/%s' %(buffer_path, backup[2]))
            if status:
                self.restore_queue.put((backup[0], '%s/%s' %(buffer_path, backup[2]), buffer_path))
            else:
                self.exit(1)
            self.download_queue.task_done()

    def main(self):

        start_time = int(time.time())

        if os.getuid() != 0:
            print "Please run as root"
            sys.exit(1)
        
        if os.path.exists(PID_FILE):
            pid = int(open(PID_FILE, 'r').read())
            try:
                os.kill(pid, 0)
                self.logger.log("Restore process is already running with PID %d" %pid)
                sys.exit(1)
            except:
                pass
        fd = open(PID_FILE,'w')
        fd.write(str(os.getpid()))
        fd.close()

        self.populate_queue()
        for i in range(self.thread_count):
            t = Thread(target=self.download_files)
            t.daemon = True
            t.start()
        t = Thread(target=self.perform_restore)
        t.daemon = True
        t.start()

        self.download_queue.join()
        t.join()
        end_time = int(time.time())
        self.logger.log("Restore completed successfully in %d seconds" %end_time-start_time)

        
if __name__ == '__main__':
    restore = Restore()
    restore.main()

