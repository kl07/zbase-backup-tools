#!/usr/bin/python
#Description: Backup s3 uploader Daemon

import sys
import os
import re
import time
import signal
import socket
import Queue
import datetime
import random
from threading import Thread, Lock
import consts
import json
from config import Config
from logger import Logger
from mc_bin_client import MemcachedClient
from util import setup_sqlite_lib, getcommandoutput, get_checkpoints_frombackup
from util import natural_sortkey, zruntime_readkey, gethostname, parse_backupname, split_by_lines
from backuplib import BackupFactory, ConnectException

# Setup the sqlite3 LD_LIBRARY_PATH before importing sqlite3
setup_sqlite_lib()
import sqlite3

class BackupProcess:
    """
    Create backups and upload incremental backups to S3
    """
    def __init__(self):
        self.exit_status = 0
        self.upload_only_mode = False
        self.first_master_backup = False
        self.resume_process_mode = False
        self.processlist = Queue.Queue()
        self.backup_lock = Lock()
        try:
            self.config = Config(consts.CONFIG_FILE)
            self.config.read()
            self.logger = Logger(tag = self.config.syslog_tag, level = self.config.log_level)
        except Exception, e:
            self.config.syslog_tag = consts.SYSLOG_TAG
            self.logger = Logger(tag = self.config.syslog_tag, level = self.config.log_level)
            self.logger.log("FAILED: Parsing config file (%s)" %(str(e)))
            self.exit(1)

        backup_process = self
        class stderrlog(object):
            def __init__(self, backup_process):
                self.parent = backup_process

            def write(self, err):
                self.parent.logger.log("FAILED: %s" %err)
                self.parent.exit(1)

        sys.stderr = stderrlog(backup_process)
        try:
            raw_buffer_list = self.config.buffer_list.split(',')
            buffer_list = set(raw_buffer_list)
            if not len(buffer_list):
                self.logger.log("FAILED: There should be atleast 1 tmpfs buffer")
                self.exit(1)

            if not os.path.exists(self.config.localsnapshot_path):
                os.makedirs(self.config.localsnapshot_path)

            if len(buffer_list) != len(raw_buffer_list):
                self.logger.log("FAILED: Duplicate buffer list found in the config")
                self.exit(1)

            f = open('/etc/mtab')
            lines = f.readlines()
            tmpfs_locations = map(lambda y: y.split(' ')[1], filter(lambda x: ' tmpfs ' in x, lines))
            for b in buffer_list:
                if len(filter(lambda x: x in b, tmpfs_locations)) == 0:
                    self.logger.log("FAILED: Buffer %s is not a tmpfs location" %b)
                    self.exit(1)

            self.free_buffer_list = Queue.Queue()
            self.backup_queue = Queue.Queue()
            for b in buffer_list:
                self.free_buffer_list.put(b)

        except Exception, e:
            self.logger.log("FAILED: %s " %str(e))
            self.exit(1)

        try:
            nagios_dir = os.path.dirname(consts.NAGIOS_BACKUP_TIME)
            os.makedirs(nagios_dir)
            os.system("chown nagios %s" %nagios_dir)
        except:
            pass

        self.update_mappingserver()
        self.logger.log("=== Starting Membase Backup Daemon ===")
        signal.signal(signal.SIGINT, self.graceful_exit)
        signal.signal(signal.SIGQUIT, self.graceful_exit)
        signal.signal(signal.SIGTERM, self.graceful_exit)

    def update_mappingserver(self):
        """
        Update mapping server env variable
        """
        mapping_server = zruntime_readkey(self.config.zruntime_user,
        self.config.zruntime_passwd,
        self.config.zruntime_namespace,
        self.config.game_id,
        self.config.zruntime_mapperkey)

        if not mapping_server:
            self.logger.log("FAILED: Unable to read from zRuntime")
            self.exit(1)
        else:
            os.environ["MAPPING_SERVER"] = mapping_server

    def getstatusoutput(self, cmd):
        return getcommandoutput(cmd, self.processlist)

    def resume_process(self):
        self.logger.log("Looking for backup files to resume upload process")
        dirpath_suffix = '%s/%s/%s' %(self.config.game_id, gethostname(), self.config.cloud)
        backup_files = {}
        split_index_group = {}
        dot_done_backup = None

        for b in list(self.free_buffer_list.queue):
            for path, dirname, filename in os.walk(os.path.join(b, dirpath_suffix)):
                if dirname == [] and filename != []:
                    backup_files[os.path.join(path, filename[0])] = b

        master_files = filter(lambda x: consts.MASTER_DIRNAME in x,
                                                backup_files.keys())
        master_files.sort(key=natural_sortkey)
        if master_files:
            m = master_files[0]
            date = m.split('/')[-2]
            s3_master_path = "s3://%s/%s/%s/" %(dirpath_suffix, consts.MASTER_DIRNAME, date)
            status, output = self.getstatusoutput("%s ls %s" %(consts.PATH_S3CMD_EXEC, s3_master_path))
            if status > 0:
                self.logger.log("FAILED: Listing master backup files from storage server (%s)" %output)
                self.exit(1)
            found_split_index = False
            for f in output.split():
                if f.endswith('.split'):
                    found_split_index = True

            if not found_split_index:
                self.logger.log("FAILED: Split index file for master backup " \
                "(%s) not found. Hence, unable to proceed resume uploading" \
                %s3_master_path)
                self.exit(1)

            dot_done_backup = master_files[-1]

        incr_files = filter(lambda x: consts.INCR_DIRNAME in x,
                                                backup_files.keys())
        for f in incr_files:
            prefix = "-".join(os.path.basename(f).split('-')[:-1])
            if not split_index_group.has_key(prefix):
                split_index_group[prefix] = []

            split_index_group[prefix].append(os.path.basename(f))
            sample_buffer = backup_files[f]
            split_index_dir = os.path.dirname(f)

        s3_incr_path = "s3://%s/%s/" %(dirpath_suffix, consts.INCR_DIRNAME)
        status, output = self.getstatusoutput("%s ls %s" %(consts.PATH_S3CMD_EXEC, s3_incr_path))
        if status > 0:
            self.logger.log("FAILED: Listing incremental files from storage server (%s)" %output)
            self.exit(1)

        s3_incr_files = filter(lambda x: x.endswith('.mbb'), output.split())
        for p in split_index_group:
            for f in s3_incr_files:
                if p in f:
                    if os.path.basename(f) not in split_index_group[p]:
                        split_index_group[p].append(os.path.basename(f))

        for sprefix in split_index_group:
            split_index_file = os.path.join(split_index_dir, "%s.split" %sprefix)
            fd = open(split_index_file, 'w')
            for filename in sorted(split_index_group[sprefix]):
                fd.write('%s\n' %filename)
            fd.close()

            status = self._upload_file(split_index_file, sample_buffer, True)
            if not status:
                self.logger.log("FAILED: Uploading split index file, %s" %split_index_file)
                self.exit(1)

            self._remove_file(split_index_file)

        for backup_file in backup_files:
            if backup_file.endswith('done') or backup_file.endswith('.split'):
                self._remove_file(backup_file)
                continue

            if not self._is_backup_valid(backup_file):
                self._remove_file(backup_file)
                self.logger.log("FAILED: Backup file %s not valid" %backup_file)
                self.exit(1)

            self.logger.log("Found backup file %s. Pusing to uploader queue" %backup_file)
            self.resume_process_mode = True
            if dot_done_backup != None and dot_done_backup == backup_file:
                item = (backup_file, backup_files[backup_file], True)
            else:
                item = (backup_file, backup_files[backup_file], False)

            self.backup_queue.put(item)

            self.free_buffer_list.queue.remove(backup_files[backup_file])

    def _upload_file(self, filepath, buffer_path, nonbackup=False):
        retries = self.config.upload_retries
        root_path = buffer_path
        if root_path[-1] == '/':
            root_path = root_path[:-1]

        if nonbackup:
	    regex = re.compile('^%s/(.*)' %root_path)
        else:
            regex = re.compile('^%s/(.*.mbb)' %root_path)
        s3suffix_path = regex.findall(filepath)[0]
        s3path = "s3://%s" %(s3suffix_path)
        self.logger.log("ATTEMPT: Uploading %s to %s " %(filepath, s3path))
        upload_cmd = "%s sync %s %s" %(consts.PATH_S3CMD_EXEC, filepath, s3path)
        self.logger.log("Executing command, %s " %upload_cmd)
        for i in range(retries):
            if i > 0:
                self.logger.log("Retrying upload for %s " %filepath)
                self.update_mappingserver()

            self.logger.log("Uploading file %s to %s " %(filepath, s3path))
            status, output = self.getstatusoutput(upload_cmd)
            if status == 0:
                break

        if status > 0:
            self.logger.log("FAILED: Upload to S3 failed for backup file %s (%s)" %(filepath, output))
            return False
        else:
            self.logger.log("SUCCESS: Uploading %s to %s (retries=%d)" %(filepath, s3path, i))
        return True


    def _is_backup_valid(self, filepath):
        try:
            db = sqlite3.connect(filepath)
            cursor = db.execute("select count(*) from cpoint_op;")
            mutation_count = cursor.fetchone()[0]
            if mutation_count == 0:
                return False
            else:
                return True

        except Exception, e:
            self.logger.log("FAILED: sqlite validation failed for %s (%s)" %(filepath, str(e)))
            return False

    def _remove_file(self, filepath):
        self.logger.log("Removing file, %s " %filepath)
        try:
            os.unlink(filepath)
            return True
        except Exception, e:
            self.logger.log("FAILED: Unable to remove file %s (%s)" %(filepath, str(e)))
            return False

    def _ss_remove_file(self, buffer_path, filepath):
        retries = self.config.upload_retries

        root_path = buffer_path
        if root_path[-1] == '/':
            root_path = root_path[:-1]

        regex = re.compile('^%s/(.*/[^/]*.mbb)' %root_path)
        s3suffix_path = regex.findall(filepath)[0]
        s3path = "s3://%s" %(s3suffix_path)
        del_cmd = "%s del %s" %(consts.PATH_S3CMD_EXEC, s3path)
        self.logger.log("Executing command, %s " %del_cmd)
        for i in range(retries):
            if i > 0:
                self.logger.log("Retrying delete for %s " %f)
                self.update_mappingserver()

            status, output = self.getstatusoutput(del_cmd)
            if status == 0:
                break
        return status

    def upload_process_thread(self):
        upload_interval = self.config.upload_interval_mins*60
        while True:
            start_time = time.time()
            if self.upload_only_mode and len(self.backup_queue.queue) == 0:
                os._exit(0)

            self.logger.log("Waiting for obtaining backup file")
            backup_item = self.backup_queue.get()
            (backup_filepath, buffer_path, dot_done) = backup_item

            if self.is_failover_needed():
                self._upload_missing_backups(backup_filepath)

            status = self._upload_file(backup_filepath, buffer_path)
            if status:
                self.free_buffer_list.put(buffer_path)
                self._remove_file(backup_filepath)
            else:
                self.exit(1)

            if dot_done:
                basepath = os.path.dirname(backup_filepath)
                donepath = os.path.join(basepath, 'done')
                f = open(donepath, 'w')
                f.write(' ')
                f.close()

                status = self._upload_file(donepath, buffer_path, True)
                self._remove_file(donepath)
                if not status:
                    self.exit(1)

            if self.resume_process_mode:
                if len(self.backup_queue.queue) == 0:
                    self.resume_process_mode = False
                else:
                    continue

            if self.upload_only_mode:
                if len(self.backup_queue.queue) == 0:
                    os._exit(0)
                continue

            end_time = time.time()
            total_time = int(end_time-start_time)
            sleep_time = upload_interval - total_time
            if sleep_time > 0:
                time.sleep(sleep_time)

    def graceful_exit(self, signum=None, frame=None):
        self.backup_lock.acquire()
        for process in self.processlist.queue:
            try:
                process.terminate()
            except:
                pass
        self.backup_lock.release()

        self.logger.log("Backup process terminated")
        if os.path.exists(consts.MBBACKUP_PID_FILE):
            os.unlink(consts.MBBACKUP_PID_FILE)
        os._exit(self.exit_status)

    def exit(self, status):
        if self.backup_lock.locked():
            self.backup_lock.release()
        self.exit_status = status
        self.graceful_exit()

    def mbstats(self, item):
        try:
            mb = MemcachedClient(host='127.0.0.1', port=11211)
            return mb.stats(item)
        except Exception, e:
            self.logger.log("FAILED: Unable to query stats from Membase:11211 (%s)" %str(e))
            self.exit(1)

    def is_cursor_valid(self, cursor_name):
        try:
            checkpoint_stats = self.mbstats('checkpoint')
        except Exception:
            self.logger.log("FAILED: Could not fetch tap stats from membase server")
            self.exit(1)

        if len(filter(lambda x: 'eq_tapq:%s' %(cursor_name) in x, checkpoint_stats)):
            return True
        return False

    def is_closed_checkpoint_moved(self):
        last_checkpoint = 0
        if os.path.exists(consts.LAST_CHECKPOINT_FILE):
            last_checkpoint = int(open(consts.LAST_CHECKPOINT_FILE).read())

        stats = self.mbstats('checkpoint')
        current_checkpoint = int(stats['vb_0:last_closed_checkpoint_id'])
        self.logger.log("Last closed checkpoint ID: %d, Current closed checkpoint ID: %d" %(last_checkpoint, current_checkpoint))
        self.current_checkpoint = current_checkpoint
        if current_checkpoint != 0 and last_checkpoint != current_checkpoint:
            return True
        else:
            return False

    def is_master_backup(self):
        now = datetime.datetime.now()
        if int(self.config.master_backup_interval_days) == 0:
            return False
        if os.path.exists(consts.LAST_MASTER_BACKUP_TIME):
            timestamp = open(consts.LAST_MASTER_BACKUP_TIME, 'r').read() 
            year, month, day, hr, mins, secs, msecs = map(lambda x: int(x), timestamp.split('-'))
            last_backup_time = datetime.datetime(year, month, day, hr, mins, secs, msecs)
            if (now - last_backup_time).total_seconds() >= int(self.config.master_backup_interval_days*24*60*60):
                return True

        return False

    def _create_master_backup_marker(self, timestamp=None):
        if timestamp == None:
            rand = random.random(0, self.config.master_backup_interval_days)
            last_backup_time = datetime.datetime.now() + datetime.timedelta(days=-(rand))
            timestamp = last_backup_time.strftime('%Y-%m-%d-%H-%M-%S-000000')

        f = open(consts.LAST_MASTER_BACKUP_TIME, 'w')
        f.write(timestamp)
        f.close()


    def backup_process_thread(self):
        interval = self.config.backup_interval_mins*60
        while True:
            dot_done = False
            start_time = time.time()
            if os.path.exists(consts.MBRESTORE_PID_FILE):
                pid = int(open(consts.MBRESTORE_PID_FILE).read())
                try:
                    os.kill(pid, 0)
                    self.logger.log("Restore process is on progress. Exiting")
                    self.exit(1)
                except:
                    pass

            if self.is_cursor_valid(consts.REPLICATION_TAPNAME):
                self.logger.log("The host is a master. Exiting")
                self.exit(1)

            if not self.is_cursor_valid(consts.BACKUP_TAPNAME):
                self.logger.log("FAILED: Registered TAP for Backup not found")
                self.exit(1)

            master_backup_attempt = self.is_master_backup()
            if self.is_closed_checkpoint_moved() or master_backup_attempt or self.first_master_backup:
                now = time.gmtime(time.time())

                datetimestamp = time.strftime('%Y-%m-%d %H:%M:%S', now)
                backup_filename = time.strftime('backup-%Y-%m-%d_%H:%M:%S-%.mbb',now)
                if self.first_master_backup or master_backup_attempt:
                    backup_dir = os.path.join(self.config.game_id,
                            gethostname(), self.config.cloud,
                            consts.MASTER_DIRNAME, "%s"
                            %(time.strftime('%Y-%m-%d', now)))
                    self.first_master_backup = False
                    full_backup = True
                    dot_done = True
                    ls_cmd = "%s ls s3://%s/" %(consts.PATH_S3CMD_EXEC, backup_dir)
                    s,o = self.getstatusoutput(ls_cmd)
                    if s > 0:
                        self.logger.log("FAILED: Execution %s" %ls_cmd)
                        self.exit(1)

                    files = filter(lambda x: x.strip()!='', o.split('\n'))
                    if files != []:
                        self.logger.log("FAILED: Master s3 directory s3://%s not empty" %backup_dir)
                        self.logger.log("FAILED: Please clear the directory and retry full backup")
                        self.exit(1)

                else:
                    last_checkpoint = 0
                    if os.path.exists(consts.LAST_CHECKPOINT_FILE):
                        last_checkpoint = int(open(consts.LAST_CHECKPOINT_FILE).read())

                    if last_checkpoint == 0:
                        backup_dir = os.path.join(self.config.game_id,
                                gethostname(), self.config.cloud,
                                consts.MASTER_DIRNAME, "%s"
                                %(time.strftime('%Y-%m-%d', now)))
                        dot_done = True
                    else:
                        backup_dir = os.path.join(self.config.game_id, gethostname(), self.config.cloud, consts.INCR_DIRNAME)
                    full_backup = False

                backup_filepath = os.path.join(backup_dir, backup_filename)
                f = open(consts.NAGIOS_BACKUP_TIME, 'w')
                f.write(str(now))
                f.close()

                self.backup_lock.acquire()
                self._rotate_local_backups()
                status = self._take_backup(backup_filepath, datetimestamp,
                                                        full_backup, dot_done)
                self.backup_lock.release()

                os.unlink(consts.NAGIOS_BACKUP_TIME)
                if status:
                    if self.first_master_backup:
                        self._create_master_backup_marker()
                        self.first_master_backup = False
                    elif master_backup_attempt:
                        self._create_master_backup_marker(time.strftime('%Y-%m-%d-%H-%M-%S-000000',now))
                else:
                    self.exit(1)
            else:
                self.logger.log("Closed checkpoint hasn't been moved. Skipping backup")

            end_time = time.time()
            total_time = int(end_time - start_time)
            sleep_time = interval - total_time
            if sleep_time > 0:
                time.sleep(sleep_time)
            else:
                sleep_time = interval + sleep_time
                if sleep_time < 0:
                    sleep_time = interval

                time.sleep(sleep_time)

    def _rotate_local_backups(self):
        """
        Delete old backups and keep X recent backups
        """
        self.logger.log("Clearing old local backups..")
        local_backups = os.listdir(self.config.localsnapshot_path)
        while len(local_backups) > self.config.localsnapshot_count:
            local_backups.sort()
            local_backups.reverse()
            old = local_backups.pop()
            self.logger.log(" - Removing local backup %s" %old)
            os.system("rm -rf %s" %(os.path.join(self.config.localsnapshot_path, old)))

    def _snapshot_backup_file(self, filepath):
        """
        Copy backup file to the local backup snapshot directory
        """

        backup_name = parse_backupname(filepath)
        local_backup_path = os.path.join(self.config.localsnapshot_path, backup_name)
        if not os.path.exists(local_backup_path):
            os.makedirs(local_backup_path)

        rv = os.system("cp %s %s" %(filepath, local_backup_path))
        if rv != 0:
            self.logger.log("ERROR: Unable to snapshot backup - %s" %filepath)
            self.exit(1)

    def is_failover_needed(self):
        """
        Figure out if a disk has gone down, in that case upload missing backups from
        available local backups.
        """
        mapping_server = os.environ["MAPPING_SERVER"]

        for retry in range(self.config.upload_retries):
            if retry > 0:
                self.update_mappingserver()

            cmd = "curl -s -L http://%s/%s" %(mapping_server, consts.BLOBRESTORE_API_PATH)
            status, output = self.getstatusoutput(cmd)
            if status > 0:
                continue

        if status > 0:
            self.logger.log("ERROR: Failed to contact mapping_server (%s) for get_host_config")
            self.exit(1)

        try:
            config = str(json.loads(output)[gethostname()])
        except:
            return False

        failover = False
        if os.path.exists(consts.DISKMAPPER_HOSTCONFIG):
            f = open(consts.DISKMAPPER_HOSTCONFIG)
            old_config = f.read()
            f.close()

            if config != old_config:
                failover = True

        f = open(consts.DISKMAPPER_HOSTCONFIG, 'w')
        f.write(config)
        f.close()

        return failover

    def _upload_missing_backups(self, exclude_backup):
        """
        Compare with the list of available backups on storage server.
        Upload missing backups using the local backups
        """

        class RetryException(Exception):
            def __init__(self, retry):
                self.message = "Retrying %d" %retry

        self.logger.log("Diskmapper hostconfig has changed. Executing localbackup based resolution")
        storage_url = 's3://%s/%s/%s/%s/' %(self.config.game_id, gethostname(), self.config.cloud, consts.INCR_DIRNAME)
        exclude_backup = os.path.basename(exclude_backup)
        for retry in range(self.config.upload_retries):
            if retry > 0:
                self.update_mappingserver()

            try:

                status, output = self.getstatusoutput("%s ls %s" %(consts.PATH_S3CMD_EXEC, storage_url))
                if status > 0:
                    raise RetryException(retry)

                def filter_mbbs(file, exclude_backup):
                    return filter(lambda x: x.endswith(".mbb") and (not exclude_backup in x), files)

                backup_set = {}

                files = map(lambda x: os.path.basename(x), split_by_lines(output))
                if consts.DEL_MANIFEST in files:
                    url = os.path.join(storage_url, consts.DEL_MANIFEST)
                    status, output = self.getstatusoutput("%s get %s /tmp/manifest.del" %(consts.PATH_S3CMD_EXEC, url))
                    if status > 0:
                        raise RetryException(retry)

                    f = open("/tmp/manifest.del")
                    output = f.read()
                    f.close()
                    os.unlink(f.name)
                    old_files = set(map(lambda x: os.path.basename(x), split_by_lines(output)))
                    files = list(set(files) - old_files)

                files = filter_mbbs(files, parse_backupname(exclude_backup))

                for fname in files:
                    bname = parse_backupname(fname)
                    backuplist = backup_set.get(bname, [])
                    backuplist.append(fname)
                    backup_set[bname] = backuplist

                local_backup_set = {}
                for lbackup in os.listdir(self.config.localsnapshot_path):
                    tmp = os.listdir(os.path.join(self.config.localsnapshot_path, lbackup))
                    if exclude_backup in tmp:
                        tmp.remove(exclude_backup)

                    local_backup_set[lbackup] = tmp

                remote_backups = backup_set.keys()
                remote_backups.sort()

                local_backups = local_backup_set.keys()
                local_backups.sort()

                if len(remote_backups) > 0:
                    last_backup = remote_backups.pop()
                else:
                    return

                try:
                    index = local_backups.index(last_backup)
                except ValueError:
                    self.logger.log("ERROR: Unable to find local copy of backup : %s" %last_backup)
                    self.exit(1)
                    return

                self.logger.log("Uploading missing backups to storage server...")
                for i in range(index, len(local_backups)):
                    backup_name = local_backups[i]
                    for f in local_backup_set[backup_name]:
                        cmd = "%s put %s %s" %(consts.PATH_S3CMD_EXEC,
                            os.path.join(self.config.localsnapshot_path, backup_name, f), storage_url)
                        self.logger.log(cmd)
                        status, output = self.getstatusoutput(cmd)
                        if status > 0:
                            raise RetryException(retry)
                return

            except RetryException:
                continue

            self.logger.log("ERROR: Upload missing backups. Retries exceeded.")
            self.exit(1)


    def _take_backup(self, backup_filepath, datetimestamp, full_backup,
                                                            dot_done=False):
        """
        Create incremental backup
        """
        total_size = 0
        size = 0
        checkpoints = []

        if full_backup:
            btype = "full"
        else:
            btype =  "incremental"

        start_time = time.time()
        self.logger.log("==== START BACKUP ====")
        self.logger.log("Creating %s Backup for %s " %(btype, datetimestamp))

        for r in range(consts.CONNECT_RETRIES):
            retry = False
            try:
                bf_instance = BackupFactory(backup_filepath, btype,
                        consts.BACKUP_TAPNAME, self.logger, 'localhost',11211) 
            except Exception, e:
                self.logger.log("FAILED: Initializing backup factory instance")
                self.logger.log(str(e))
                self.exit(1)

            while not bf_instance.is_complete():
                self.logger.log("Waiting for obtaining free ramfs buffer")
                buffer_path = self.free_buffer_list.get()
                self.logger.log("Obtained buffer %s " %buffer_path)
                try:
                    filepath = bf_instance.create_next_split(buffer_path)
                    size = os.stat(filepath).st_size
                    total_size += size

                    if size <= 4096:
                        if not self._is_backup_valid(filepath):
                            self.logger.log("FAILED: Backup size is %d" %size)
                            raise Exception("Backup is invalid")

                    try:
                        checkpoints.extend(get_checkpoints_frombackup(filepath))
                    except Exception, e:
                        self.logger.log("FAILED: sqlite file %s is corrupt (%s)" %(backup_filepath, str(e)))
                        raise Exception("Sqlite file corrupt")

                    # Take local snapshot
                    if not full_backup and last_backup_checkpoint != 0:
                        self._snapshot_backup_file(filepath)

                    if bf_instance.is_complete() and dot_done:
                        self.backup_queue.put((filepath, buffer_path, True))
                    else:
                        self.backup_queue.put((filepath, buffer_path, False))

                    self.logger.log("Added %s to upload queue" %filepath)
                    retry = False

                except ConnectException:
                    retry = True
                    time.sleep(1)
                    break

                except Exception, e:
                    self.logger.log(str(e))
                    self.logger.log("FAILED: Creating Backup for %s" %(datetimestamp))
                    split_file = bf_instance.get_current_split()
                    if split_file:
                        self._remove_file(split_file)
                    self.exit(1)

            if retry:
                continue
            else:
                break

        if retry:
            self.logger.log("FAILED: TAP connection retrying failed (%d)" %consts.CONNECT_RETRIES)
            self.exit(1)

        checkpoints.sort()

        if os.path.exists(consts.LAST_CHECKPOINT_FILE) and not full_backup:
            f = open(consts.LAST_CHECKPOINT_FILE)
            last_backup_checkpoint = int(f.read())
            f.close()
        else:
            last_backup_checkpoint = 0

        if len(checkpoints):
            if last_backup_checkpoint > 0:
                if last_backup_checkpoint + 1 != checkpoints[0]:
                    self.logger.log("FAILED: Invalid backup. Last backup checkpoint = %d, New backup checkpoint = %s" %(last_backup_checkpoint, checkpoints[0]))
                    self.exit(1)
                else:
                    self.logger.log("Last backup_checkpoint: %d Current backup checkpoints: %s" %(last_backup_checkpoint, str(checkpoints)))

            f = open(consts.LAST_CHECKPOINT_FILE, 'w')
            f.write(str(checkpoints[-1]))
            f.close()
            split_files = map(lambda x: os.path.basename(x), map(lambda y: y[-1], bf_instance.list_splits()))
            split_index_path = "%s.split" %"-".join(filepath.split('-')[:-1])
            fd = open(split_index_path, 'w')
            for split_file in split_files:
                fd.write("%s\n" %split_file)
            fd.close()

            # Snapshot split-index to local directory
            if not full_backup and last_backup_checkpoint != 0:
                self._snapshot_backup_file(split_index_path)

            status = self._upload_file(split_index_path, buffer_path, True)
            if status:
                self._remove_file(split_index_path)
            else:
                self.logger.log("FAILED: Uploading split index file %s" %split_index_path)
                self.exit(1)
        else:
            self.logger.log("FAILED: Current backup contains zero checkpoints")
            self.exit(1)

        end_time = time.time()
        time_taken = end_time - start_time
        self.logger.log("Completed Backup for %s" %(datetimestamp))
        self.logger.log("BACKUP SUMMARY: type:%s size:%d, time-taken: %d, backup-file:%s split-count:%d" %(btype, total_size, int(time_taken), backup_filepath, len(bf_instance.list_splits())))
        self.logger.log("==== END BACKUP ====")
        return True

    def mainloop(self):
        if self.first_master_backup:
            for b in self.free_buffer_list.queue:
                try:
                    os.system("rm -rf %s/*" %b)
                except Exception, e:
                    self.logger.log("FAILED: Unable to clear buffers (%s)" %str(e))

        self.resume_process()
        backup_thread = Thread(target=self.backup_process_thread)
        upload_thread = Thread(target=self.upload_process_thread)
        backup_thread.setDaemon(True)
        upload_thread.setDaemon(True)
        backup_thread.start()
        upload_thread.start()
        while True:
            time.sleep(100)

    def upload_only_loop(self):
        self.upload_only_mode = True
        self.resume_process()
        self.upload_process_thread()

if __name__ == '__main__':
    if os.getuid() != 0:
        print "Please run as root"
        sys.exit(1)

    try:
        command = sys.argv[1]
    except:
        command = None

    if command == 'start' or command == 'start-with-fullbackup':
        if os.path.exists(consts.MBBACKUP_PID_FILE):
            pid = int(open(consts.MBBACKUP_PID_FILE).read())
            try:
                os.kill(pid, 0)
                print "Backup Daemon with PID:%d is already running" %pid
                os._exit(1)
            except:
                pass

        try:
            pid = os.fork()
            if pid == 0:
                f = open(consts.MBBACKUP_PID_FILE,'w')
                f.write(str(os.getpid()))
                f.close()
	    else:
                os._exit(0)
        except:
            os._exit(2)

        core = BackupProcess()
        if command == 'start-with-fullbackup':
            core.first_master_backup = True

        core.mainloop()
    elif command == "stop":
        if os.path.exists(consts.MBBACKUP_PID_FILE):
            print "Issuing stop command for Backup Daemon"
            pid = int(open(consts.MBBACKUP_PID_FILE).read())
            try:
                os.kill(pid, 0)
            except:
                print "Backup daemon is not already running"
                sys.exit(0)

            os.kill(pid, signal.SIGTERM)
            while True:
                try:
                    os.kill(pid, 0)
                except:
                    print "Backup daemon stopped successfully"
                    sys.exit(0)
                time.sleep(5)
        else:
           print "Backup Daemon is not running"
           os._exit(1)

    elif command == 'upload-only':
        core = BackupProcess()
        core.upload_only_loop()
        sys.exit(0)

    else:
        print "Usage: %s command\ncommand = start or stop\n" %sys.argv[0]
